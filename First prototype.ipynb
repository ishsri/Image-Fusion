{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torchvision\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import h5py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from colorspacious import cspace_converter\n",
    "from matplotlib import cm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(r\"Dataset/Brats2018_validation_data_sep_channels_train_val_mix.h5\", 'r')\n",
    "val_data = hf['data'][()]     #`data` is now an ndarray\n",
    "val_data_tensor = torch.from_numpy(val_data).float()\n",
    "\n",
    "hf.close()\n",
    "\n",
    "hf_val = h5py.File(r\"Dataset/binary_mask_val.h5\", 'r')\n",
    "binary_mask_t1ce = hf_val['binary_mask_val_closed'][()]\n",
    "binary_mask_t1ce = torch.from_numpy(binary_mask_t1ce).float().to(device)\n",
    "\n",
    "hf_val.close()\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    for j in range(4):\n",
    "        val_data[i,j,:,:] = (val_data[i,j,:,:] - np.min(val_data[i,j,:,:])) / (np.max(val_data[i,j,:,:]) - np.min(val_data[i,j,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the network\n",
    "class def_model(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(def_model, self).__init__()\n",
    "        # Define the model based on the paper https://arxiv.org/abs/1810.91654\n",
    "        ###############\n",
    "        #Encoder\n",
    "        ###############\n",
    "        self.conv1 = nn.Sequential( #input shape (,2,240,240)\n",
    "                         nn.Conv2d(in_channels=2, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,32,240,240)   \n",
    "        ##### res like layer 1#####\n",
    "        self.res1 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels  = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,32,240,240)\n",
    "        ##### downsample conv like layer#####\n",
    "        self.conv2 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120)        \n",
    "        #####res like layer 2#####\n",
    "        self.res2 = nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120) \n",
    "        #####conv like layer#####\n",
    "        self.conv3 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120)\n",
    "        #####res like layer 3#####\n",
    "        self.res3  =     nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120) \n",
    "        ##### downsample conv like layer 2#####\n",
    "        self.conv4 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        #####res like layer 4#####\n",
    "        self.res4 = nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        #####conv like layer#####\n",
    "        self.conv5 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60)\n",
    "        #####res like layer 5#####\n",
    "        self.res5  =     nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        ##### downsample conv like layer 3#####\n",
    "        self.conv6 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####res like layer 6#####\n",
    "        self.res6 = nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv7 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        #####res like layer 7#####\n",
    "        self.res7  =     nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv8 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####res like layer 8#####\n",
    "        self.res8 = nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv9 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        #####res like layer 9#####\n",
    "        self.res9  =     nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        ###############\n",
    "        #Decoder\n",
    "        ###############\n",
    "        ##### upsample conv like layer 3#####\n",
    "        self.conv10 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,128,60,60)\n",
    "        \n",
    "        #####res like layer 10#####\n",
    "        self.res10  =    nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,128,60,60)\n",
    "        \n",
    "        ##### upsample conv like layer 4#####\n",
    "        self.conv11 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,64,120,120)\n",
    "        \n",
    "        #####res like layer 11#####\n",
    "        self.res11  =    nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,64,120,120)   \n",
    "        \n",
    "        ##### upsample conv like layer 4#####\n",
    "        self.conv12 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,32,240,240)\n",
    "        \n",
    "        #####res like layer 11#####\n",
    "        self.res12  =    nn.Sequential( #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,32,240,240)       \n",
    "        \n",
    "        #####conv like layer#####\n",
    "        self.conv13 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 1, kernel_size  = 3, stride= 1, padding = 1)) #output shape (,1,240,240)\n",
    " \n",
    "        #####sigmoid layer#####\n",
    "        self.sigmoid1 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #conv1\n",
    "        x1 = self.conv1(x)\n",
    "        #res1\n",
    "        x2 = self.res1(x1)\n",
    "        #conv2 \n",
    "        x3 = self.conv2(x2)\n",
    "        #res2\n",
    "        x4 = self.res2(x3)\n",
    "        #conv3\n",
    "        x5 = self.conv3(x4)\n",
    "        #res3\n",
    "        x6 = self.res3(x5)\n",
    "        #conv4\n",
    "        x7 = self.conv4(x6)\n",
    "        #res4\n",
    "        x8 = self.res4(x7)\n",
    "        #conv5\n",
    "        x9 = self.conv5(x8)  \n",
    "        #res5\n",
    "        x10 = self.res5(x9)\n",
    "        #conv6\n",
    "        x11 = self.conv6(x10)\n",
    "        #res6\n",
    "        x12 = self.res6(x11)\n",
    "        #conv7\n",
    "        x13 = self.conv7(x12)\n",
    "        #res7\n",
    "        x14 = self.res7(x13)\n",
    "        #conv8\n",
    "        x15 = self.conv8(x14)\n",
    "        #res8\n",
    "        x16 = self.res8(x15)\n",
    "        #conv9\n",
    "        x17 = self.conv9(x16)\n",
    "        #res9\n",
    "        x18 = self.res9(x17)\n",
    "        #conv10\n",
    "        x19 = self.conv10(x18)\n",
    "        # add operation\n",
    "        add1 = x19 + x10\n",
    "        #res10\n",
    "        x20 = self.res10(add1)\n",
    "        #conv11\n",
    "        x21 = self.conv11(x20)\n",
    "        #add operation\n",
    "        add2 = x21 + x6\n",
    "        #res11\n",
    "        x22 = self.res11(add2)\n",
    "        #conv12\n",
    "        x23 = self.conv12(x22)\n",
    "        #add operation\n",
    "        add3 = x23 + x2\n",
    "        #res12\n",
    "        x24 = self.res12(add3)\n",
    "        #conv13\n",
    "        x25 = self.conv13(x24)\n",
    "        #sigmoid \n",
    "        x26 = self.sigmoid1(x25)\n",
    "        return x26\n",
    "        #execute the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = def_model().to(device)\n",
    "gpu_ids = [0]\n",
    "model = model.float()\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(model, gpu_ids)\n",
    "    cudnn.benchmark = True\n",
    "        \n",
    "mod = torch.load(r\"C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1\\Final run\\epoch\\model_0.49.pt\")\n",
    "model_state_dict = mod[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = ['0.00', '0.25', '0.49', '0.75', '0.90', '1.0']\n",
    "\n",
    "path = ['weight_map', 'weight_map_masked', 'weight_map_norm', 'fused_image', 'fused_image_norm', 'fused_image_masked', 'rgb', 'hsv']\n",
    "\n",
    "clrmaps = ['PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu', 'RdYlBu','RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic']\n",
    "\n",
    "for lm in lambda_values:\n",
    "    for pth in path:\n",
    "        parent_path = f\"C:/Users/ishan/Desktop/Image Fusion/Fusion_R1/Inference_p2/\"\n",
    "        dir_path = parent_path + lm + '/' + pth\n",
    "        os.makedirs (dir_path, exist_ok=True)\n",
    "    \n",
    "    for cm in clrmaps:\n",
    "        colormap_path_wm = parent_path + lm + '/colormaps/weight_map/' + cm\n",
    "        colormap_path_fi= parent_path + lm + '/colormaps/fused_image/' + cm\n",
    "        overlay_path = parent_path + lm + '/colormaps/overlay/' + cm\n",
    "        os.makedirs(colormap_path_wm, exist_ok=True)\n",
    "        os.makedirs(colormap_path_fi, exist_ok=True)\n",
    "        os.makedirs(overlay_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter.tix import COLUMN\n",
    "from matplotlib.pyplot import colormaps\n",
    "from pyrsistent import v\n",
    "\n",
    "\n",
    "total_val_images = 1153\n",
    "\n",
    "lam = '0.49'\n",
    "\n",
    "for i in range(115, 116):\n",
    "    with torch.no_grad():\n",
    "        input_val  = val_data_tensor[i,2:,:,:].to(device)\n",
    "\n",
    "        input_val = torch.unsqueeze(input_val, 0)\n",
    "\n",
    "        weight_map_val = model(input_val)\n",
    "        \n",
    "        fused_val = weight_map_val*input_val[:,0:1,:,:] + (1-weight_map_val)*input_val[:,1:2,:,:]\n",
    "        \n",
    "        weight_map_val_norm = 2*weight_map_val\n",
    "\n",
    "        weight_map_val_norm = (weight_map_val_norm - torch.min(weight_map_val_norm))/(torch.max(weight_map_val_norm) - torch.min(weight_map_val_norm))\n",
    "\n",
    "        fused_val_norm = weight_map_val_norm*input_val[:,0:1,:,:] + (1-weight_map_val_norm)*input_val[:,1:2,:,:]\n",
    "\n",
    "        weight_map_new = torch.mul(weight_map_val_norm, binary_mask_t1ce[i,:,:,:])\n",
    "\n",
    "        fused_val_new = weight_map_new*input_val[:,0:1,:,:] + (1-weight_map_new)*input_val[:,1:2,:,:]\n",
    "\n",
    "        lm_dict = {'weight_map': weight_map_val, 'weight_map_masked': weight_map_new, 'weight_map_norm' : weight_map_val_norm, 'fused_image': fused_val, \n",
    "        'fused_image_norm':fused_val_norm, 'fused_image_masked':fused_val_new}\n",
    "\n",
    "        \n",
    "        #torchvision.utils.save_image(weight_map_val, r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1/inference_p2/'+ lam + '/weight_map/weight_map_{}.png'.format(i))\n",
    "        #torchvision.utils.save_image(weight_map_val_norm, r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1/inference_p2/'+ lam + '/weight_map_norm/weight_map_norm_{}.png'.format(i))\n",
    "        #torchvision.utils.save_image(weight_map_new, r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1/inference_p2/'+ lam + '/weight_map_masked/weight_map_masked_{}.png'.format(i))\n",
    "        \n",
    "        \n",
    "        #torchvision.utils.save_image(fused_val, r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1/inference_p2/'+ lam + '/fused_image/fused_image_{}.png'.format(i))\n",
    "        #torchvision.utils.save_image(fused_val_norm, r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1/inference_p2/'+ lam + '/fused_image_norm/fused_image_norm_{}.png'.format(i))\n",
    "        #torchvision.utils.save_image(fused_val_new, r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1/inference_p2/'+ lam + '/fused_image_masked/fused_image_masked_{}.png'.format(i))\n",
    "        \n",
    "        height = fused_val.shape[2]\n",
    "        width = fused_val.shape[3]\n",
    "        rgb = np.zeros((height, width,3))\n",
    "        ones = np.zeros((height, width))\n",
    "                \n",
    "        rgb[:,:,0] = weight_map_new.cpu()\n",
    "        rgb[:,:,1] = ones\n",
    "        rgb[:,:,2] = fused_val.cpu()\n",
    "        \n",
    "        hsv = mpl.colors.rgb_to_hsv(rgb)\n",
    "         \n",
    "        #plt.imsave(r'C:/Users/ishan/Desktop/Image Fusion/Fusion_R1/Inference_p2/'+ lam + '/rgb/coupled_rgb_{}.png'.format(i), rgb)\n",
    "     \n",
    "        #plt.imsave(r'C:/Users/ishan/Desktop/Image Fusion/Fusion_R1/Inference_p2/'+ lam + '/hsv/coupled_hsv_{}.png'.format(i), hsv)\n",
    "\n",
    "        clrmaps = ['PiYG', 'PRGn', 'BrBG', 'PuOr', 'RdGy', 'RdBu', 'RdYlBu','RdYlGn', 'Spectral', 'coolwarm', 'bwr', 'seismic']\n",
    "\n",
    "        weight_map_new = weight_map_new.cpu().numpy()\n",
    "        fused_val_new = (fused_val_new.cpu().numpy())\n",
    "        \n",
    "        \n",
    "        #for cm in clrmaps:\n",
    "           # plt.imsave(r'C:/Users/ishan/Desktop/Image Fusion/Fusion_R1/Inference_p2/' + lam + '/colormaps/weight_map/' + cm + '/colormap_{}.png'.format(i), weight_map_new[0,0,:,:], cmap = cm)\n",
    "           # plt.imsave(r'C:/Users/ishan/Desktop/Image Fusion/Fusion_R1/Inference_p2/' + lam + '/colormaps/fused_image/' + cm + '/colormap_{}.png'.format(i), fused_val_new[0,0,:,:], cmap = cm)\n",
    "            \n",
    "        for cm in clrmaps[9:10]:\n",
    "            my_cm = mpl.cm.get_cmap(cm)\n",
    "            fused_val_new_cm = my_cm(fused_val_new[0,0,:,:])\n",
    "            weight_map_new_cm = my_cm(weight_map_new[0,0,:,:])\n",
    "            weight_map_new_cm = weight_map_new_cm[:,:,0:3]\n",
    "            hsv_wm = mpl.colors.rgb_to_hsv(weight_map_new_cm)\n",
    "            #plt.imshow(hsv_wm)\n",
    "            hsv_wm_cross = hsv_wm\n",
    "            hsv_wm_cross[:,:,2] = fused_val_new[0,0,:,:]\n",
    "            plt.imshow(hsv_wm_cross)\n",
    "            hsv_wm_mul = hsv_wm\n",
    "            hsv_wm_mul[:,:,2] = hsv_wm[:,:,2]*fused_val_new[0,0,:,:]\n",
    "            plt.imshow(hsv_wm_mul)\n",
    "            weight_map_back = mpl.colors.hsv_to_rgb(hsv_wm_cross)\n",
    "            plt.imshow(weight_map_back)\n",
    "            # fig = plt.figure()\n",
    "            # rows = 4\n",
    "            # columns = 1\n",
    "            # fig.add_subplot(rows, columns, 1)\n",
    "            #plt.imshow(fused_val_new[0,0,:,:], cmap=\"gray\")\n",
    "            # plt.title(\"Fused_Image\")\n",
    "            # fig.add_subplot(rows, columns, 2)\n",
    "            #plt.imshow(weight_map_new_cm)\n",
    "            # plt.title(\"Weight_map_colormapped\")\n",
    "            # fig.add_subplot(rows, columns, 3)\n",
    "            #plt.imshow(hsv_wm)\n",
    "            # plt.title(\"Weight_map_hsv\")\n",
    "            # fig.add_subplot(rows, columns, 4)\n",
    "            #plt.imshow(hsv_wm_cross)\n",
    "            # plt.title(\"hsv_fused_value_channel\")\n",
    "\n",
    "            \n",
    "            #rgb_cm = my_cm(rgb)\n",
    "            #plt.imsave(r'rgb_cm.png', rgb_cm)\n",
    "            # overlay_arr = np.zeros((height, width, 3))\n",
    "            # ones = np.zeros((height, width))\n",
    "            # overlay_arr[:,:,0] = weight_map_new_cm[:,:,0]\n",
    "            # overlay_arr[:,:,1] = ones\n",
    "            # overlay_arr[:,:,2] = fused_val_new_cm[:,:,1]\n",
    "            #plt.imsave(r'C:/Users/ishan/Desktop/Image Fusion/Fusion_R1/Inference_p2/' + lam + '/colormaps/overlay/' + cm + '/overlay_{}.png'.format(i), overlay_arr)\n",
    "            \n",
    "            # plt.imshow(fused_val_new[0,0,:,:], cmap='gray')\n",
    "            # plt.imshow(weight_map_new_cm, interpolation= 'nearest', alpha=0.9)\n",
    "            # plt.axis('off')\n",
    "            #plt.colorbar()\n",
    "            #from PIL import Image\n",
    "            #im1 = Image.fromarray(weight_map_new_cm)\n",
    "            #im2 = Image.fromarray(fused_val_new[0,0,:,:])\n",
    "            #new_image = Image.blend(weight_map_new_cm, fused_val_new[0,0,:,:], 0.5)\n",
    "            #new_image.save(\"overlay.png\",\"PNG\")\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_wm_mul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_wm[:,:,2] = fused_val_new[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import image\n",
    "\n",
    "im1 = Image.open(r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1\\inference_p2\\0.49\\colormaps\\weight_map\\RdGy\\colormap_115.png')\n",
    "im2 = Image.open(r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R1\\inference_p2\\0.49\\fused_image_masked\\fused_image_masked_115.png')\n",
    "\n",
    "new_im = Image.blend(im1, im2, 0.5)\n",
    "new_im.save('overlay.png', 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " im = plt.imshow(fused_val_new[0,0,:,:], cmap='PiYG')\n",
    " cbar = plt.colorbar()\n",
    " cbar.set_label('Pixel values (0 to 1)')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cm = mpl.cm.get_cmap('PiYG')\n",
    "image = my_cm(fused_val_new[0,0,:,:])\n",
    "plt.imshow(image)\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Pixel values (0 to 1)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colormaps(fused_val_new[0,0,:,:], cmap='PiYG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2305bcac1fe6e87e4fddffb71fb75c78508e0ebae27a562f1b87979be3d4f77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
