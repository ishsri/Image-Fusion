{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import h5py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import random\n",
    "\n",
    "hf = h5py.File(r\"/home/h3/issr292b/image_fusion/Brats2018_validation_data_sep_channels_train_val_mix.h5\", 'r')\n",
    "train_data = hf['data'][()]     #`data` is now an ndarray\n",
    "train_data_tensor = torch.from_numpy(train_data).float()\n",
    "\n",
    "hf.close()\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(4):\n",
    "        train_data[i,j,:,:] = (train_data[i,j,:,:] - np.min(train_data[i,j,:,:])) / (np.max(train_data[i,j,:,:]) - np.min(train_data[i,j,:,:]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_t1ce = train_data[:,2,:,:]\n",
    "train_data_flair = train_data[:,3,:,:]\n",
    "height = train_data.shape[2]\n",
    "width = train_data.shape[3]\n",
    "total_train_images = train_data.shape[0]\n",
    "r_channel = np.zeros((total_train_images, height, width, 3))\n",
    "r_channel[:,:,:,0] = train_data_t1ce\n",
    "r_channel[:,:,:,1] = np.zeros((total_train_images, height, width))\n",
    "r_channel[:,:,:,2] = np.zeros((total_train_images, height, width))\n",
    "\n",
    "g_channel = np.zeros((total_train_images, height, width, 3))\n",
    "g_channel[:,:,:,1] = train_data_flair\n",
    "g_channel[:,:,:,0] = np.zeros((total_train_images, height, width))\n",
    "g_channel[:,:,:,2] = np.zeros((total_train_images, height, width))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel_transpose = np.transpose(r_channel, [0,2,1,3])\n",
    "r_channel_transpose = np.transpose(r_channel, [0,3,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_channel_transpose = np.transpose(g_channel, [0,2,1,3])\n",
    "g_channel_transpose = np.transpose(g_channel, [0,3,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array = np.concatenate((r_channel_transpose,g_channel_transpose), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 6, 240, 240)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_new = h5py.File('fusion_r2_validation_data.h5', 'w')\n",
    "hf_new.create_dataset('g_channel', data = g_channel_transpose)\n",
    "hf_new.create_dataset('r_channel', data = r_channel_transpose)\n",
    "hf_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hf_new_1 = h5py.File(r\"C:\\Users\\ishan\\Desktop\\Image Fusion\\fusion_r2_training_data.h5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_t1ce = torch.from_numpy(train_data_t1ce)\n",
    "#train_data_flair = torch.from_numpy(train_data_flair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torchvision.utils.save_image(train_data_t1ce[0,:,:], r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R2\\original_t1ce_{}.png'.format(i))\n",
    "#torchvision.utils.save_image(train_data_flair[0,:,:], r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R2\\original_flair_{}.png'.format(i))\n",
    "#plt.imsave(r'C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R2\\r_channel_{}.jpeg'.format(i), r_channel[0,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2305bcac1fe6e87e4fddffb71fb75c78508e0ebae27a562f1b87979be3d4f77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
