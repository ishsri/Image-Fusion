{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torchvision\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import h5py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(r\"C:\\Users\\ishan\\Desktop\\Image Fusion\\Dataset\\fusion_r2_validation_data.h5\", 'r')\n",
    "val_flair_tensor = hf['g_channel'][()]\n",
    "val_t1ce_tensor = hf['r_channel'][()]\n",
    "hf.close()\n",
    "val_data_tensor = np.concatenate((val_t1ce_tensor, val_flair_tensor), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_data_tensor)):\n",
    "    for j in range(6):\n",
    "        val_data_tensor[i,j,:,:] = (val_data_tensor[i,j,:,:] - np.min(val_data_tensor[i,j,:,:])) / (np.max(val_data_tensor[i,j,:,:]) - np.min(val_data_tensor[i,j,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the network\n",
    "class def_model(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(def_model, self).__init__()\n",
    "        # Define the model based on the paper https://arxiv.org/abs/1810.11654\n",
    "        ###############\n",
    "        #Encoder\n",
    "        ###############\n",
    "        self.conv1 = nn.Sequential( #input shape (,2,240,240)\n",
    "                         nn.Conv2d(in_channels=6, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,32,240,240)   \n",
    "        ##### res like layer 1#####\n",
    "        self.res1 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels  = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,32,240,240)\n",
    "        ##### downsample conv like layer#####\n",
    "        self.conv2 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120)        \n",
    "        #####res like layer 2#####\n",
    "        self.res2 = nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120) \n",
    "        #####conv like layer#####\n",
    "        self.conv3 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120)\n",
    "        #####res like layer 3#####\n",
    "        self.res3  =     nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120) \n",
    "        ##### downsample conv like layer 2#####\n",
    "        self.conv4 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        #####res like layer 4#####\n",
    "        self.res4 = nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        #####conv like layer#####\n",
    "        self.conv5 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60)\n",
    "        #####res like layer 5#####\n",
    "        self.res5  =     nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        ##### downsample conv like layer 3#####\n",
    "        self.conv6 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####res like layer 6#####\n",
    "        self.res6 = nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv7 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        #####res like layer 7#####\n",
    "        self.res7  =     nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv8 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####res like layer 8#####\n",
    "        self.res8 = nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv9 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        #####res like layer 9#####\n",
    "        self.res9  =     nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        ###############\n",
    "        #Decoder\n",
    "        ###############\n",
    "        ##### upsample conv like layer 3#####\n",
    "        self.conv10 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,128,60,60)\n",
    "        \n",
    "        #####res like layer 10#####\n",
    "        self.res10  =    nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,128,60,60)\n",
    "        \n",
    "        ##### upsample conv like layer 4#####\n",
    "        self.conv11 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,64,120,120)\n",
    "        \n",
    "        #####res like layer 11#####\n",
    "        self.res11  =    nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,64,120,120)   \n",
    "        \n",
    "        ##### upsample conv like layer 4#####\n",
    "        self.conv12 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,32,240,240)\n",
    "        \n",
    "        #####res like layer 11#####\n",
    "        self.res12  =    nn.Sequential( #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,32,240,240)       \n",
    "        \n",
    "        #####conv like layer#####\n",
    "        self.conv13 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 3, kernel_size  = 3, stride= 1, padding = 1)) #output shape (,1,240,240)\n",
    " \n",
    "        #####sigmoid layer#####\n",
    "        self.sigmoid1 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #conv1\n",
    "        x1 = self.conv1(x)\n",
    "        #res1\n",
    "        x2 = self.res1(x1)\n",
    "        #conv2 \n",
    "        x3 = self.conv2(x2)\n",
    "        #res2\n",
    "        x4 = self.res2(x3)\n",
    "        #conv3\n",
    "        x5 = self.conv3(x4)\n",
    "        #res3\n",
    "        x6 = self.res3(x5)\n",
    "        #conv4\n",
    "        x7 = self.conv4(x6)\n",
    "        #res4\n",
    "        x8 = self.res4(x7)\n",
    "        #conv5\n",
    "        x9 = self.conv5(x8)  \n",
    "        #res5\n",
    "        x10 = self.res5(x9)\n",
    "        #conv6\n",
    "        x11 = self.conv6(x10)\n",
    "        #res6\n",
    "        x12 = self.res6(x11)\n",
    "        #conv7\n",
    "        x13 = self.conv7(x12)\n",
    "        #res7\n",
    "        x14 = self.res7(x13)\n",
    "        #conv8\n",
    "        x15 = self.conv8(x14)\n",
    "        #res8\n",
    "        x16 = self.res8(x15)\n",
    "        #conv9\n",
    "        x17 = self.conv9(x16)\n",
    "        #res9\n",
    "        x18 = self.res9(x17)\n",
    "        #conv10\n",
    "        x19 = self.conv10(x18)\n",
    "        # add operation\n",
    "        add1 = x19 + x10\n",
    "        #res10\n",
    "        x20 = self.res10(add1)\n",
    "        #conv11\n",
    "        x21 = self.conv11(x20)\n",
    "        #add operation\n",
    "        add2 = x21 + x6\n",
    "        #res11\n",
    "        x22 = self.res11(add2)\n",
    "        #conv12\n",
    "        x23 = self.conv12(x22)\n",
    "        #add operation\n",
    "        add3 = x23 + x2\n",
    "        #res12\n",
    "        x24 = self.res12(add3)\n",
    "        #conv13\n",
    "        x25 = self.conv13(x24)\n",
    "        #sigmoid \n",
    "        x26 = self.sigmoid1(x25)\n",
    "        return x26\n",
    "        #execute the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = def_model().to(device)\n",
    "gpu_ids = [0]\n",
    "model = model.float()\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(model, gpu_ids)\n",
    "    cudnn.benchmark = True\n",
    "        \n",
    "mod = torch.load(r\"C:\\Users\\ishan\\Desktop\\Image Fusion\\Fusion_R2\\epoch\\model_r2.pt\")\n",
    "model_state_dict = mod[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_tensor = torch.from_numpy(val_data_tensor).float()\n",
    "total_val_images = 1153\n",
    "\n",
    "for i in range(0, total_val_images):\n",
    "    with torch.no_grad():\n",
    "        input_val  = val_data_tensor[i:,:,:,:].to(device)\n",
    "        #input_val = torch.unsqueeze(input_val, 0)\n",
    "        weight_map_val = model(input_val)\n",
    "        torchvision.utils.save_image(weight_map_val, 'C:/Users/ishan/Desktop/Image Fusion/Fusion_R2/inference/ssim_0,1/fused_image/count_{}.png'.format(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2305bcac1fe6e87e4fddffb71fb75c78508e0ebae27a562f1b87979be3d4f77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
