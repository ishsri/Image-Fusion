{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torchvision\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import h5py\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(r\"/projects/p084/p_discoret/fusion_r2_validation_data.h5\", 'r')\n",
    "val_flair_tensor = hf['g_channel'][()]\n",
    "val_t1ce_tensor = hf['r_channel'][()]\n",
    "hf.close()\n",
    "val_data_tensor = np.concatenate((val_t1ce_tensor, val_flair_tensor), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\AppData\\Local\\Temp/ipykernel_20996/3689746255.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  val_data_tensor[i,j,:,:] = (val_data_tensor[i,j,:,:] - np.min(val_data_tensor[i,j,:,:])) / (np.max(val_data_tensor[i,j,:,:]) - np.min(val_data_tensor[i,j,:,:]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_data_tensor)):\n",
    "    for j in range(6):\n",
    "        val_data_tensor[i,j,:,:] = (val_data_tensor[i,j,:,:] - np.min(val_data_tensor[i,j,:,:])) / (np.max(val_data_tensor[i,j,:,:]) - np.min(val_data_tensor[i,j,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the network\n",
    "class def_model(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(def_model, self).__init__()\n",
    "        # Define the model based on the paper https://arxiv.org/abs/1810.11654\n",
    "        ###############\n",
    "        #Encoder\n",
    "        ###############\n",
    "        self.conv1 = nn.Sequential( #input shape (,2,240,240)\n",
    "                         nn.Conv2d(in_channels=6, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,32,240,240)   \n",
    "        ##### res like layer 1#####\n",
    "        self.res1 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels  = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,32,240,240)\n",
    "        ##### downsample conv like layer#####\n",
    "        self.conv2 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120)        \n",
    "        #####res like layer 2#####\n",
    "        self.res2 = nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120) \n",
    "        #####conv like layer#####\n",
    "        self.conv3 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120)\n",
    "        #####res like layer 3#####\n",
    "        self.res3  =     nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,64,120,120) \n",
    "        ##### downsample conv like layer 2#####\n",
    "        self.conv4 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        #####res like layer 4#####\n",
    "        self.res4 = nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        #####conv like layer#####\n",
    "        self.conv5 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60)\n",
    "        #####res like layer 5#####\n",
    "        self.res5  =     nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,128,60,60) \n",
    "        ##### downsample conv like layer 3#####\n",
    "        self.conv6 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size  = 4, stride= 2, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####res like layer 6#####\n",
    "        self.res6 = nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv7 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        #####res like layer 7#####\n",
    "        self.res7  =     nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv8 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####res like layer 8#####\n",
    "        self.res8 = nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30) \n",
    "        #####conv like layer#####\n",
    "        self.conv9 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        #####res like layer 9#####\n",
    "        self.res9  =     nn.Sequential( #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.ReLU()) #output shape (,256,30,30)\n",
    "        ###############\n",
    "        #Decoder\n",
    "        ###############\n",
    "        ##### upsample conv like layer 3#####\n",
    "        self.conv10 = nn.Sequential(  #input shape (,256,30,30)\n",
    "                         nn.Conv2d(in_channels = 256, out_channels = 128, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,128,60,60)\n",
    "        \n",
    "        #####res like layer 10#####\n",
    "        self.res10  =    nn.Sequential( #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,128,60,60)\n",
    "        \n",
    "        ##### upsample conv like layer 4#####\n",
    "        self.conv11 = nn.Sequential(  #input shape (,128,60,60)\n",
    "                         nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,64,120,120)\n",
    "        \n",
    "        #####res like layer 11#####\n",
    "        self.res11  =    nn.Sequential( #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,64,120,120)   \n",
    "        \n",
    "        ##### upsample conv like layer 4#####\n",
    "        self.conv12 = nn.Sequential(  #input shape (,64,120,120)\n",
    "                         nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.Upsample(scale_factor=2, mode='nearest')) #output shape (,32,240,240)\n",
    "        \n",
    "        #####res like layer 11#####\n",
    "        self.res12  =    nn.Sequential( #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         #nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)#,\n",
    "        )#nn.ReLU()) #output shape (,32,240,240)       \n",
    "        \n",
    "        #####conv like layer#####\n",
    "        self.conv13 = nn.Sequential(  #input shape (,32,240,240)\n",
    "                         nn.Conv2d(in_channels = 32, out_channels = 3, kernel_size  = 3, stride= 1, padding = 1)) #output shape (,1,240,240)\n",
    " \n",
    "        #####sigmoid layer#####\n",
    "        self.sigmoid1 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #conv1\n",
    "        x1 = self.conv1(x)\n",
    "        #res1\n",
    "        x2 = self.res1(x1)\n",
    "        #conv2 \n",
    "        x3 = self.conv2(x2)\n",
    "        #res2\n",
    "        x4 = self.res2(x3)\n",
    "        #conv3\n",
    "        x5 = self.conv3(x4)\n",
    "        #res3\n",
    "        x6 = self.res3(x5)\n",
    "        #conv4\n",
    "        x7 = self.conv4(x6)\n",
    "        #res4\n",
    "        x8 = self.res4(x7)\n",
    "        #conv5\n",
    "        x9 = self.conv5(x8)  \n",
    "        #res5\n",
    "        x10 = self.res5(x9)\n",
    "        #conv6\n",
    "        x11 = self.conv6(x10)\n",
    "        #res6\n",
    "        x12 = self.res6(x11)\n",
    "        #conv7\n",
    "        x13 = self.conv7(x12)\n",
    "        #res7\n",
    "        x14 = self.res7(x13)\n",
    "        #conv8\n",
    "        x15 = self.conv8(x14)\n",
    "        #res8\n",
    "        x16 = self.res8(x15)\n",
    "        #conv9\n",
    "        x17 = self.conv9(x16)\n",
    "        #res9\n",
    "        x18 = self.res9(x17)\n",
    "        #conv10\n",
    "        x19 = self.conv10(x18)\n",
    "        # add operation\n",
    "        add1 = x19 + x10\n",
    "        #res10\n",
    "        x20 = self.res10(add1)\n",
    "        #conv11\n",
    "        x21 = self.conv11(x20)\n",
    "        #add operation\n",
    "        add2 = x21 + x6\n",
    "        #res11\n",
    "        x22 = self.res11(add2)\n",
    "        #conv12\n",
    "        x23 = self.conv12(x22)\n",
    "        #add operation\n",
    "        add3 = x23 + x2\n",
    "        #res12\n",
    "        x24 = self.res12(add3)\n",
    "        #conv13\n",
    "        x25 = self.conv13(x24)\n",
    "        #sigmoid \n",
    "        x26 = self.sigmoid1(x25)\n",
    "        return x26\n",
    "        #execute the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def_model(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res3): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res4): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res5): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res6): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv7): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res7): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv8): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res8): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv9): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (res9): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv10): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  )\n",
       "  (res10): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conv11): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  )\n",
       "  (res11): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conv12): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  )\n",
       "  (res12): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conv13): Sequential(\n",
       "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (sigmoid1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = def_model().to(device)\n",
    "gpu_ids = [0]\n",
    "model = model.float()\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(model, gpu_ids)\n",
    "    cudnn.benchmark = True\n",
    "        \n",
    "mod = torch.load(r\"/home/h3/issr292b/image_fusion/epoch/model_r2_0.49.pt\")\n",
    "model_state_dict = mod[\"model_state_dict\"]\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20996/3787546847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_data_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtotal_val_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1153\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_val_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "val_data_tensor = torch.from_numpy(val_data_tensor).float()\n",
    "total_val_images = 1153\n",
    "\n",
    "for i in range(0, total_val_images):\n",
    "    with torch.no_grad():\n",
    "        input_val  = val_data_tensor[i:,:,:,:].to(device)\n",
    "        #input_val = torch.unsqueeze(input_val, 0)\n",
    "        weight_map_val = model(input_val)\n",
    "        torchvision.utils.save_image(weight_map_val, '/home/h3/issr292b/image_fusion/inference_r2/0.49/weight_map/count_{}.png'.format(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2305bcac1fe6e87e4fddffb71fb75c78508e0ebae27a562f1b87979be3d4f77c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
